{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7nGjMsHOZIP"
      },
      "source": [
        "# Clip Tokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku2PLmLxMreH"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install Requirements\n",
        "\n",
        "print(\"This will take a couple of minutes...\")\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "!pip install -q transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Setup Pipeline\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from transformers import CLIPTokenizer\n",
        "from transformers import file_utils\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "# =======================================\n",
        "# setup pipeline\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "MODEL_PATH = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(f'{MODEL_PATH}', revision=\"fp16\", torch_dtype = torch.float16, safety_checker = None)\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "tokenizer = CLIPTokenizer.from_pretrained(MODEL_PATH, subfolder=\"tokenizer\",revision=\"fp16\")\n",
        "\n",
        "# tokenizer/vocab.json files are normally saved in cache e.g.\n",
        "# /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/xxxxx/tokenizer/vocab.json\n",
        "\n",
        "# transformers cache directory\n",
        "cache_dir = file_utils.default_cache_path\n",
        "\n",
        "# find the vocab file\n",
        "for root, dirs, files in os.walk(cache_dir):\n",
        "    for file in files:\n",
        "        if file == \"vocab.json\":\n",
        "            vocab_file_path = os.path.join(root, file)\n",
        "            print(f\"Found vocab file at: {vocab_file_path}\")\n",
        "            break\n",
        "\n"
      ],
      "metadata": {
        "id": "5Vic9ZYEYY3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "K-akUTZHw7Ls"
      },
      "outputs": [],
      "source": [
        "#@title 3. Setup Tokenize() Function\n",
        "\n",
        "import json\n",
        "\n",
        "# =======================================\n",
        "# for coloring text\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    RED = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "# ===========================================================================\n",
        "\n",
        "def tokenize(prompt_or_caption):\n",
        "\n",
        "  with open(vocab_file_path, \"r\", encoding='utf-8') as f:\n",
        "    vocab = json.load(f)\n",
        "    vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "  print(f'vocab size: {tokenizer.vocab_size}')\n",
        "  print(f'max length: {tokenizer.model_max_length}')\n",
        "\n",
        "  bos_encoded_input = tokenizer.encode('<|startoftext|>', add_special_tokens=False)\n",
        "  eos_encoded_input = tokenizer.encode(f'{tokenizer.eos_token}', add_special_tokens=False)\n",
        "  print(f'{bcolors.OKCYAN}special token (bos): {tokenizer.bos_token}: {bos_encoded_input}{bcolors.ENDC}')\n",
        "  print(f'{bcolors.OKCYAN}special token (eos): {tokenizer.eos_token}: {eos_encoded_input}{bcolors.ENDC}')\n",
        "\n",
        "  # print(f'special token (unk): {tokenizer.unk_token}')\n",
        "  # print(f'special token (pad): {tokenizer.pad_token}\\n')\n",
        "\n",
        "  print(f'{bcolors.OKGREEN}GREEN = Within the 77-Token Limit{bcolors.ENDC}')\n",
        "  print(f'{bcolors.RED}RED = Outside 77-Token Limit{bcolors.ENDC}\\n')\n",
        "\n",
        "  #inputs = tokenizer(sys.argv[1], padding=True)\n",
        "  inputs = tokenizer(f'{prompt_or_caption}', padding=True)\n",
        "  value = sum(inputs[\"input_ids\"])\n",
        "  value_str = str(value)\n",
        "  token_data = ''\n",
        "\n",
        "\n",
        "  #  print the token ids in rows of 10\n",
        "  row_length = 10\n",
        "  final_string_ids = '' # final string for the ids\n",
        "  final_string_words = '' # final string for the words/subwords\n",
        "\n",
        "  # Find the length of the longest word (for padding)\n",
        "  max_word_length = max(len(vocab[id]) for id in inputs[\"input_ids\"])\n",
        "\n",
        "  for i in range(0, len(inputs[\"input_ids\"]), row_length):\n",
        "    # Extract a row's worth of numbers\n",
        "    row = inputs[\"input_ids\"][i:i + row_length]\n",
        "\n",
        "    #  inputs[\"input_ids\"][x] = the ID Numbers\n",
        "    #  vocab[inputs[\"input_ids\"][x]] = the sub-word\n",
        "\n",
        "    # Initialize an empty string for the new row\n",
        "    row_string_ids = \"\"\n",
        "    row_string_words = \"\"\n",
        "\n",
        "    # Iterate through each token-id in the row, using j as index\n",
        "    for j, id in enumerate(row):\n",
        "        # here, id = inputs[\"input_ids\"][j]\n",
        "        # Calculate the global index of the token\n",
        "        global_index = i + j\n",
        "\n",
        "        word = vocab[id]\n",
        "        padded_word = word.ljust(max_word_length)\n",
        "\n",
        "        # Determine the color based on the global token index\n",
        "        if global_index < 77:\n",
        "            color = bcolors.OKGREEN\n",
        "        else:\n",
        "            color = bcolors.RED\n",
        "\n",
        "        # Append the colored token to the row string\n",
        "        row_string_ids += f\"{color}{id:5d}{bcolors.ENDC}\"\n",
        "        row_string_words += f\"{color}{padded_word}{bcolors.ENDC}\"\n",
        "\n",
        "        if j < len(row) - 1:\n",
        "            row_string_ids += \", \"  # Add comma and space between tokens\n",
        "            row_string_words += \", \"  # Add comma and space between tokens\n",
        "\n",
        "\n",
        "    # Determine if a comma should be added at the end\n",
        "    end_comma = ',' if i + row_length < len(inputs[\"input_ids\"]) else ''\n",
        "\n",
        "    # add to final strings\n",
        "    final_string_ids += row_string_ids + end_comma + '\\n'\n",
        "    final_string_words  += row_string_words + end_comma + '\\n'\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print(final_string_ids)\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print(final_string_words)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Run\n",
        "\n",
        "PROMPT_CAPTION = \"A charming photo of a small bunny. He is wearing a suit. masterpiece, ultra-quality, hyperrealistic, RAW photo, highly detailed, 4k, medium shot, cinematic photography, natural texture, action shot, XF IQ4, 150MP, 50mm, ISO 1000, 1/250s, natural light\"\n",
        "\n",
        "tokenize(PROMPT_CAPTION)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW_QsPJ_cA01",
        "outputId": "a6c25dbf-a2ca-4377-bdf2-8d1a3db04ac0"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 49408\n",
            "max length: 77\n",
            "\u001b[96mspecial token (bos): <|startoftext|>: [49406]\u001b[0m\n",
            "\u001b[96mspecial token (eos): <|endoftext|>: [49407]\u001b[0m\n",
            "\u001b[92mGREEN = Within the 77-Token Limit\u001b[0m\n",
            "\u001b[91mRED = Outside 77-Token Limit\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[92m49406\u001b[0m, \u001b[92m  320\u001b[0m, \u001b[92m12177\u001b[0m, \u001b[92m 1125\u001b[0m, \u001b[92m  539\u001b[0m, \u001b[92m  320\u001b[0m, \u001b[92m 2442\u001b[0m, \u001b[92m 9258\u001b[0m, \u001b[92m  269\u001b[0m, \u001b[92m  797\u001b[0m,\n",
            "\u001b[92m  533\u001b[0m, \u001b[92m 3309\u001b[0m, \u001b[92m  320\u001b[0m, \u001b[92m 3940\u001b[0m, \u001b[92m  269\u001b[0m, \u001b[92m12066\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 8118\u001b[0m, \u001b[92m  268\u001b[0m, \u001b[92m 3027\u001b[0m,\n",
            "\u001b[92m  267\u001b[0m, \u001b[92m 7997\u001b[0m, \u001b[92m16157\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 6323\u001b[0m, \u001b[92m 1125\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 5302\u001b[0m, \u001b[92m12609\u001b[0m, \u001b[92m  267\u001b[0m,\n",
            "\u001b[92m  275\u001b[0m, \u001b[92m  330\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 8675\u001b[0m, \u001b[92m 2000\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m25602\u001b[0m, \u001b[92m 2108\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 3288\u001b[0m,\n",
            "\u001b[92m16505\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 1816\u001b[0m, \u001b[92m 2000\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m35274\u001b[0m, \u001b[92m19996\u001b[0m, \u001b[92m  275\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m  272\u001b[0m,\n",
            "\u001b[92m  276\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m 1246\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m  276\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m 2848\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m12263\u001b[0m, \u001b[92m  272\u001b[0m,\n",
            "\u001b[92m  271\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m  272\u001b[0m, \u001b[92m  270\u001b[0m, \u001b[92m  273\u001b[0m, \u001b[92m  276\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m  338\u001b[0m,\n",
            "\u001b[92m  267\u001b[0m, \u001b[92m 3288\u001b[0m, \u001b[92m 1395\u001b[0m, \u001b[92m49407\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[92m<|startoftext|>\u001b[0m, \u001b[92ma</w>          \u001b[0m, \u001b[92mcharming</w>   \u001b[0m, \u001b[92mphoto</w>      \u001b[0m, \u001b[92mof</w>         \u001b[0m, \u001b[92ma</w>          \u001b[0m, \u001b[92msmall</w>      \u001b[0m, \u001b[92mbunny</w>      \u001b[0m, \u001b[92m.</w>          \u001b[0m, \u001b[92mhe</w>         \u001b[0m,\n",
            "\u001b[92mis</w>         \u001b[0m, \u001b[92mwearing</w>    \u001b[0m, \u001b[92ma</w>          \u001b[0m, \u001b[92msuit</w>       \u001b[0m, \u001b[92m.</w>          \u001b[0m, \u001b[92mmasterpiece</w>\u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92multra</w>      \u001b[0m, \u001b[92m-</w>          \u001b[0m, \u001b[92mquality</w>    \u001b[0m,\n",
            "\u001b[92m,</w>          \u001b[0m, \u001b[92mhyper          \u001b[0m, \u001b[92mrealistic</w>  \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92mraw</w>        \u001b[0m, \u001b[92mphoto</w>      \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92mhighly</w>     \u001b[0m, \u001b[92mdetailed</w>   \u001b[0m, \u001b[92m,</w>          \u001b[0m,\n",
            "\u001b[92m4</w>          \u001b[0m, \u001b[92mk</w>          \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92mmedium</w>     \u001b[0m, \u001b[92mshot</w>       \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92mcinematic</w>  \u001b[0m, \u001b[92mphotography</w>\u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92mnatural</w>    \u001b[0m,\n",
            "\u001b[92mtexture</w>    \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92maction</w>     \u001b[0m, \u001b[92mshot</w>       \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92mxf</w>         \u001b[0m, \u001b[92miq</w>         \u001b[0m, \u001b[92m4</w>          \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92m1</w>          \u001b[0m,\n",
            "\u001b[92m5</w>          \u001b[0m, \u001b[92m0</w>          \u001b[0m, \u001b[92mmp</w>         \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92m5</w>          \u001b[0m, \u001b[92m0</w>          \u001b[0m, \u001b[92mmm</w>         \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92miso</w>        \u001b[0m, \u001b[92m1</w>          \u001b[0m,\n",
            "\u001b[92m0</w>          \u001b[0m, \u001b[92m0</w>          \u001b[0m, \u001b[92m0</w>          \u001b[0m, \u001b[92m,</w>          \u001b[0m, \u001b[92m1</w>          \u001b[0m, \u001b[92m/</w>          \u001b[0m, \u001b[92m2</w>          \u001b[0m, \u001b[92m5</w>          \u001b[0m, \u001b[92m0</w>          \u001b[0m, \u001b[92ms</w>          \u001b[0m,\n",
            "\u001b[92m,</w>          \u001b[0m, \u001b[92mnatural</w>    \u001b[0m, \u001b[92mlight</w>      \u001b[0m, \u001b[92m<|endoftext|>  \u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szYvHNJPWI3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}