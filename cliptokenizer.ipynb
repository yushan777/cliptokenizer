{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7nGjMsHOZIP"
      },
      "source": [
        "# Clip Tokenizer\n",
        "\n",
        "https://github.com/yushan777/cliptokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku2PLmLxMreH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install Requirements\n",
        "\n",
        "print(\"This will take a couple of minutes...\")\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "!pip install -q transformers\n",
        "print(\"Finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Setup Pipeline\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from transformers import CLIPTokenizer\n",
        "from transformers import file_utils\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "\n",
        "print(\"This will take a couple of minutes...\")\n",
        "# =======================================\n",
        "# setup pipeline\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "MODEL_PATH = \"runwayml/stable-diffusion-v1-5\"\n",
        "# sdxl has 2 tokenizers and two dictionaries, but they are the same\n",
        "# MODEL_PATH = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(f'{MODEL_PATH}', variant=\"fp16\", torch_dtype = torch.float16)\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "tokenizer = CLIPTokenizer.from_pretrained(MODEL_PATH, subfolder=\"tokenizer\",variant=\"fp16\")\n",
        "\n",
        "# tokenizer/vocab.json files are normally saved in cache e.g.\n",
        "# /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/xxxxx/tokenizer/vocab.json\n",
        "\n",
        "# transformers cache directory\n",
        "cache_dir = file_utils.default_cache_path\n",
        "\n",
        "# find the vocab file\n",
        "for root, dirs, files in os.walk(cache_dir):\n",
        "    for file in files:\n",
        "        if file == \"vocab.json\":\n",
        "            vocab_file_path = os.path.join(root, file)\n",
        "            print(f\"Found vocab file at: {vocab_file_path}\")\n",
        "            break\n",
        "\n",
        "print(\"Finished.\")\n"
      ],
      "metadata": {
        "id": "5Vic9ZYEYY3y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "K-akUTZHw7Ls",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3. Setup Tokenize() Function\n",
        "\n",
        "import json\n",
        "import textwrap\n",
        "# ===========================================================================\n",
        "# for coloring text\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    RED = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "# ===========================================================================\n",
        "\n",
        "def tokenize(prompt_or_caption, show_end_of_word_marker):\n",
        "\n",
        "  with open(vocab_file_path, \"r\", encoding='utf-8') as f:\n",
        "    vocab = json.load(f)\n",
        "    vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "  print(f'vocab size: {tokenizer.vocab_size}')\n",
        "  print(f'max length: {tokenizer.model_max_length}')\n",
        "  bos_encoded_input = tokenizer.encode('<|startoftext|>', add_special_tokens=False)\n",
        "  eos_encoded_input = tokenizer.encode(f'{tokenizer.eos_token}', add_special_tokens=False)\n",
        "  print(f'{bcolors.OKCYAN}special token (bos): {tokenizer.bos_token}: {bos_encoded_input}{bcolors.ENDC}')\n",
        "  print(f'{bcolors.OKCYAN}special token (eos): {tokenizer.eos_token}: {eos_encoded_input}{bcolors.ENDC}')\n",
        "  print(f'{bcolors.OKGREEN}GREEN = Token within the 77-Token Limit{bcolors.ENDC}')\n",
        "  print(f'{bcolors.RED}RED = Token outside 77-Token Limit{bcolors.ENDC}\\n')\n",
        "\n",
        "  #inputs = tokenizer(sys.argv[1], padding=True)\n",
        "  inputs = tokenizer(f'{prompt_or_caption}', padding=True)\n",
        "\n",
        "\n",
        "  print(textwrap.fill(prompt_or_caption, width=100))\n",
        "\n",
        "  #  print the token ids in rows of 10\n",
        "  row_length = 10\n",
        "  final_string_ids = '' # final string for the ids\n",
        "  final_string_words = '' # final string for the words/subwords\n",
        "\n",
        "  # Find the length of the longest word (for padding)\n",
        "  max_word_length = max(len(vocab[id]) for id in inputs[\"input_ids\"])\n",
        "\n",
        "  for i in range(0, len(inputs[\"input_ids\"]), row_length):\n",
        "    # Extract a row's worth of ids\n",
        "    row = inputs[\"input_ids\"][i:i + row_length]\n",
        "\n",
        "    #  inputs[\"input_ids\"][x] = the ID Numbers\n",
        "    #  vocab[inputs[\"input_ids\"][x]] = the sub-word\n",
        "\n",
        "    # Initialize an empty string for the new row\n",
        "    row_string_ids = \"\"\n",
        "    row_string_words = \"\"\n",
        "\n",
        "    # Iterate through each token-id in the row, using j as index\n",
        "    for j, id in enumerate(row):\n",
        "        # here, id = inputs[\"input_ids\"][j]\n",
        "        # Calculate the global index of the token\n",
        "        global_index = i + j\n",
        "\n",
        "        if show_end_of_word_marker:\n",
        "          word = vocab[id]\n",
        "        else:\n",
        "          word = vocab[id].replace('</w>', '')  # Strip end-of-word marker\n",
        "\n",
        "        padded_word = word.ljust(max_word_length)\n",
        "\n",
        "        # Determine the color based on the global token index\n",
        "        if global_index < 77:\n",
        "            color = bcolors.OKGREEN\n",
        "        else:\n",
        "            color = bcolors.RED\n",
        "\n",
        "        # Append the colored token to the row string\n",
        "        row_string_ids += f\"{color}{id:5d}{bcolors.ENDC}\"\n",
        "        row_string_words += f\"{color}{padded_word}{bcolors.ENDC}\"\n",
        "\n",
        "        if j < len(row) - 1:\n",
        "            row_string_ids += \", \"  # Add comma and space between tokens\n",
        "            row_string_words += \", \"  # Add comma and space between tokens\n",
        "\n",
        "\n",
        "    # Determine if a comma should be added at the end\n",
        "    end_comma = ',' if i + row_length < len(inputs[\"input_ids\"]) else ''\n",
        "\n",
        "    # add to final strings\n",
        "    final_string_ids += row_string_ids + end_comma + '\\n'\n",
        "    final_string_words  += row_string_words + end_comma + '\\n'\n",
        "\n",
        "  print('\\n')\n",
        "  token_count = global_index+1\n",
        "  if token_count <= 77:\n",
        "    print(f'Token Count: {bcolors.OKGREEN}{token_count}{bcolors.ENDC}')\n",
        "  else:\n",
        "    print(f'Token Count: {bcolors.RED}{token_count}{bcolors.ENDC}')\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print(final_string_ids)\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print(final_string_words)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Run\n",
        "\n",
        "show_end_of_word_marker = False\n",
        "\n",
        "PROMPT_CAPTION = \"A charming photo of a small bunny. He is wearing a suit. masterpiece, ultra-quality, hyperrealistic, RAW photo, highly detailed, 4k, medium shot, cinematic photography, natural texture, action shot, XF IQ4, 150MP, 50mm, ISO 1000, 1/250s, natural light\"\n",
        "\n",
        "tokenize(PROMPT_CAPTION, show_end_of_word_marker)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW_QsPJ_cA01",
        "outputId": "cf22205c-cee4-4a04-8569-0839e133472f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 49408\n",
            "max length: 77\n",
            "\u001b[96mspecial token (bos): <|startoftext|>: [49406]\u001b[0m\n",
            "\u001b[96mspecial token (eos): <|endoftext|>: [49407]\u001b[0m\n",
            "\u001b[92mGREEN = Within the 77-Token Limit\u001b[0m\n",
            "\u001b[91mRED = Outside 77-Token Limit\u001b[0m\n",
            "\n",
            "A charming photo of a small bunny. He is wearing a suit. masterpiece, ultra-quality, hyperrealistic,\n",
            "RAW photo, highly detailed, 4k, medium shot, cinematic photography, natural texture, action shot, XF\n",
            "IQ4, 150MP, 50mm, ISO 1000, 1/250s, natural light\n",
            "\n",
            "\n",
            "Token Count: \u001b[92m74\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[92m49406\u001b[0m, \u001b[92m  320\u001b[0m, \u001b[92m12177\u001b[0m, \u001b[92m 1125\u001b[0m, \u001b[92m  539\u001b[0m, \u001b[92m  320\u001b[0m, \u001b[92m 2442\u001b[0m, \u001b[92m 9258\u001b[0m, \u001b[92m  269\u001b[0m, \u001b[92m  797\u001b[0m,\n",
            "\u001b[92m  533\u001b[0m, \u001b[92m 3309\u001b[0m, \u001b[92m  320\u001b[0m, \u001b[92m 3940\u001b[0m, \u001b[92m  269\u001b[0m, \u001b[92m12066\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 8118\u001b[0m, \u001b[92m  268\u001b[0m, \u001b[92m 3027\u001b[0m,\n",
            "\u001b[92m  267\u001b[0m, \u001b[92m 7997\u001b[0m, \u001b[92m16157\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 6323\u001b[0m, \u001b[92m 1125\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 5302\u001b[0m, \u001b[92m12609\u001b[0m, \u001b[92m  267\u001b[0m,\n",
            "\u001b[92m  275\u001b[0m, \u001b[92m  330\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 8675\u001b[0m, \u001b[92m 2000\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m25602\u001b[0m, \u001b[92m 2108\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 3288\u001b[0m,\n",
            "\u001b[92m16505\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m 1816\u001b[0m, \u001b[92m 2000\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m35274\u001b[0m, \u001b[92m19996\u001b[0m, \u001b[92m  275\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m  272\u001b[0m,\n",
            "\u001b[92m  276\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m 1246\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m  276\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m 2848\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m12263\u001b[0m, \u001b[92m  272\u001b[0m,\n",
            "\u001b[92m  271\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m  267\u001b[0m, \u001b[92m  272\u001b[0m, \u001b[92m  270\u001b[0m, \u001b[92m  273\u001b[0m, \u001b[92m  276\u001b[0m, \u001b[92m  271\u001b[0m, \u001b[92m  338\u001b[0m,\n",
            "\u001b[92m  267\u001b[0m, \u001b[92m 3288\u001b[0m, \u001b[92m 1395\u001b[0m, \u001b[92m49407\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\u001b[92m<|startoftext|>\u001b[0m, \u001b[92ma              \u001b[0m, \u001b[92mcharming       \u001b[0m, \u001b[92mphoto          \u001b[0m, \u001b[92mof             \u001b[0m, \u001b[92ma              \u001b[0m, \u001b[92msmall          \u001b[0m, \u001b[92mbunny          \u001b[0m, \u001b[92m.              \u001b[0m, \u001b[92mhe             \u001b[0m,\n",
            "\u001b[92mis             \u001b[0m, \u001b[92mwearing        \u001b[0m, \u001b[92ma              \u001b[0m, \u001b[92msuit           \u001b[0m, \u001b[92m.              \u001b[0m, \u001b[92mmasterpiece    \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92multra          \u001b[0m, \u001b[92m-              \u001b[0m, \u001b[92mquality        \u001b[0m,\n",
            "\u001b[92m,              \u001b[0m, \u001b[92mhyper          \u001b[0m, \u001b[92mrealistic      \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92mraw            \u001b[0m, \u001b[92mphoto          \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92mhighly         \u001b[0m, \u001b[92mdetailed       \u001b[0m, \u001b[92m,              \u001b[0m,\n",
            "\u001b[92m4              \u001b[0m, \u001b[92mk              \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92mmedium         \u001b[0m, \u001b[92mshot           \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92mcinematic      \u001b[0m, \u001b[92mphotography    \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92mnatural        \u001b[0m,\n",
            "\u001b[92mtexture        \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92maction         \u001b[0m, \u001b[92mshot           \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92mxf             \u001b[0m, \u001b[92miq             \u001b[0m, \u001b[92m4              \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92m1              \u001b[0m,\n",
            "\u001b[92m5              \u001b[0m, \u001b[92m0              \u001b[0m, \u001b[92mmp             \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92m5              \u001b[0m, \u001b[92m0              \u001b[0m, \u001b[92mmm             \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92miso            \u001b[0m, \u001b[92m1              \u001b[0m,\n",
            "\u001b[92m0              \u001b[0m, \u001b[92m0              \u001b[0m, \u001b[92m0              \u001b[0m, \u001b[92m,              \u001b[0m, \u001b[92m1              \u001b[0m, \u001b[92m/              \u001b[0m, \u001b[92m2              \u001b[0m, \u001b[92m5              \u001b[0m, \u001b[92m0              \u001b[0m, \u001b[92ms              \u001b[0m,\n",
            "\u001b[92m,              \u001b[0m, \u001b[92mnatural        \u001b[0m, \u001b[92mlight          \u001b[0m, \u001b[92m<|endoftext|>  \u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szYvHNJPWI3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}