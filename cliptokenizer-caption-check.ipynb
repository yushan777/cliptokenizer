{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7nGjMsHOZIP"
      },
      "source": [
        "# Clip Tokenizer : Prompt/Caption Checker\n",
        "\n",
        "Given a prompt or caption, it will tokenize it and display which tokens fall within 77 token limit and outside\n",
        "\n",
        "https://github.com/yushan777/cliptokenizer\n",
        "\n",
        "Run each cell in order.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku2PLmLxMreH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install Requirements\n",
        "\n",
        "print(\"This will take a couple of minutes...\")\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "!pip install -q transformers\n",
        "print(\"Finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Select Model\n",
        "\n",
        "MODEL = 'SD1.5' # @param ['SD1.5', 'SD2.1', 'SDXL']\n",
        "\n",
        "# @markdown SD1.5, SD2.1 and SDXL all use the same dictionaries. So it really doesn't matter which one you choose.<br />\n",
        "# @markdown SDXL has two dictionaries, but they are also the same\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RiJ1k6ym94EP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Setup Pipeline\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from transformers import CLIPTokenizer\n",
        "from transformers import file_utils\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "\n",
        "print(\"This will take a couple of minutes...\")\n",
        "# =======================================\n",
        "# setup pipeline\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "MODEL_PATH = ''\n",
        "if MODEL == 'SD1.5':\n",
        "  MODEL_PATH = 'runwayml/stable-diffusion-v1-5'\n",
        "elif MODEL == 'SD2.1':\n",
        "  MODEL_PATH = 'stabilityai/stable-diffusion-2-1'\n",
        "elif MODEL == 'SDXL':\n",
        "  MODEL_PATH = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "\n",
        "    # MODEL_PATH = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "# MODEL_PATH = \"runwayml/stable-diffusion-v1-5\"\n",
        "# sdxl has 2 tokenizers and two dictionaries, but they are the same\n",
        "\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(f'{MODEL_PATH}', variant=\"fp16\", torch_dtype = torch.float16)\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "tokenizer = CLIPTokenizer.from_pretrained(MODEL_PATH, subfolder=\"tokenizer\",variant=\"fp16\")\n",
        "\n",
        "# tokenizer/vocab.json files are normally saved in cache e.g.\n",
        "# /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/xxxxx/tokenizer/vocab.json\n",
        "\n",
        "# transformers cache directory\n",
        "cache_dir = file_utils.default_cache_path\n",
        "\n",
        "# find the vocab file\n",
        "print(\"locating cached vocab.json\")\n",
        "for root, dirs, files in os.walk(cache_dir):\n",
        "    for file in files:\n",
        "        if file == \"vocab.json\":\n",
        "            vocab_file_path = os.path.join(root, file)\n",
        "            print(f\"Found vocab file at: {vocab_file_path}\")\n",
        "            break\n",
        "\n",
        "print(\"Finished.\")\n"
      ],
      "metadata": {
        "id": "5Vic9ZYEYY3y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "K-akUTZHw7Ls",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 4. Setup Tokenize() Function\n",
        "\n",
        "import json\n",
        "import textwrap\n",
        "# ===========================================================================\n",
        "# for coloring text\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    RED = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "# ===========================================================================\n",
        "\n",
        "def tokenize(prompt_or_caption, show_end_of_word_marker):\n",
        "\n",
        "  with open(vocab_file_path, \"r\", encoding='utf-8') as f:\n",
        "    vocab = json.load(f)\n",
        "    vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "  print(f'vocab size: {tokenizer.vocab_size}')\n",
        "  print(f'max length: {tokenizer.model_max_length}')\n",
        "  bos_encoded_input = tokenizer.encode('<|startoftext|>', add_special_tokens=False)\n",
        "  eos_encoded_input = tokenizer.encode(f'{tokenizer.eos_token}', add_special_tokens=False)\n",
        "  print(f'{bcolors.OKCYAN}special token (bos): {tokenizer.bos_token}: {bos_encoded_input}{bcolors.ENDC}')\n",
        "  print(f'{bcolors.OKCYAN}special token (eos): {tokenizer.eos_token}: {eos_encoded_input}{bcolors.ENDC}')\n",
        "  print(f'{bcolors.OKGREEN}GREEN = Token within the 77-Token Limit{bcolors.ENDC}')\n",
        "  print(f'{bcolors.RED}RED = Token outside 77-Token Limit{bcolors.ENDC}\\n')\n",
        "\n",
        "  #inputs = tokenizer(sys.argv[1], padding=True)\n",
        "  inputs = tokenizer(f'{prompt_or_caption}', padding=True)\n",
        "\n",
        "\n",
        "  print(textwrap.fill(prompt_or_caption, width=100))\n",
        "\n",
        "  #  print the token ids in rows of 10\n",
        "  row_length = 10\n",
        "  final_string_ids = '' # final string for the ids\n",
        "  final_string_words = '' # final string for the words/subwords\n",
        "\n",
        "  # Find the length of the longest word (for padding)\n",
        "  max_word_length = max(len(vocab[id]) for id in inputs[\"input_ids\"])\n",
        "\n",
        "  for i in range(0, len(inputs[\"input_ids\"]), row_length):\n",
        "    # Extract a row's worth of ids\n",
        "    row = inputs[\"input_ids\"][i:i + row_length]\n",
        "\n",
        "    #  inputs[\"input_ids\"][x] = the ID Numbers\n",
        "    #  vocab[inputs[\"input_ids\"][x]] = the sub-word\n",
        "\n",
        "    # Initialize an empty string for the new row\n",
        "    row_string_ids = \"\"\n",
        "    row_string_words = \"\"\n",
        "\n",
        "    # Iterate through each token-id in the row, using j as index\n",
        "    for j, id in enumerate(row):\n",
        "        # here, id = inputs[\"input_ids\"][j]\n",
        "        # Calculate the global index of the token\n",
        "        global_index = i + j\n",
        "\n",
        "        if show_end_of_word_marker:\n",
        "          word = vocab[id]\n",
        "        else:\n",
        "          word = vocab[id].replace('</w>', '')  # Strip end-of-word marker\n",
        "\n",
        "        padded_word = word.ljust(max_word_length)\n",
        "\n",
        "        # Determine the color based on the global token index\n",
        "        if global_index < 77:\n",
        "            color = bcolors.OKGREEN\n",
        "        else:\n",
        "            color = bcolors.RED\n",
        "\n",
        "        # Append the colored token to the row string\n",
        "        row_string_ids += f\"{color}{id:5d}{bcolors.ENDC}\"\n",
        "        row_string_words += f\"{color}{padded_word}{bcolors.ENDC}\"\n",
        "\n",
        "        if j < len(row) - 1:\n",
        "            row_string_ids += \", \"  # Add comma and space between tokens\n",
        "            row_string_words += \", \"  # Add comma and space between tokens\n",
        "\n",
        "\n",
        "    # Determine if a comma should be added at the end\n",
        "    end_comma = ',' if i + row_length < len(inputs[\"input_ids\"]) else ''\n",
        "\n",
        "    # add to final strings\n",
        "    final_string_ids += row_string_ids + end_comma + '\\n'\n",
        "    final_string_words  += row_string_words + end_comma + '\\n'\n",
        "\n",
        "  print('\\n')\n",
        "  token_count = global_index+1\n",
        "  if token_count <= 77:\n",
        "    print(f'Token Count: {bcolors.OKGREEN}{token_count}{bcolors.ENDC}')\n",
        "  else:\n",
        "    print(f'Token Count: {bcolors.RED}{token_count}{bcolors.ENDC}')\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print(final_string_ids)\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print(final_string_words)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Run\n",
        "\n",
        "show_end_of_word_marker = False\n",
        "\n",
        "PROMPT_CAPTION = \"cinematic photo film noir style, woman, highly detailed, sharp focus, ultra sharpness, monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic, hyperreal, hyperrealistic, hyperrealism, hyperrealistic painting, mkdrgs style, (b&w, Monochromatic, Film Photography:1.3), Photorealistic, Hyperrealistic, Hyperdetailed, film noir, analog style, soft lighting, subsurface scattering, realistic, heavy shadow, masterpiece, best quality, ultra realistic, 8k, golden ratio, Intricate, High Detail, film photography, soft focus, dramatic lighting, 35mm photograph, film, bokeh, professional, 4k, highly detailed\" # @param {type:\"string\"}\n",
        "\n",
        "tokenize(PROMPT_CAPTION, show_end_of_word_marker)\n",
        "\n"
      ],
      "metadata": {
        "id": "WW_QsPJ_cA01",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}